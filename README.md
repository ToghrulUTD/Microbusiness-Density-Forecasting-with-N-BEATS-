# Project Overview
The goal of this project is to develop an accurate model trained on U.S. county-level data to predict monthly microbusiness density in a given area. This would potentially help policymakers gain visibility into microbusinesses, a growing trend of very small entities. Additional information will enable new policies and programs to improve the success and impact of these smallest of businesses.
More detailed information about the dataset and objective can be found [on Kaggle](https://www.kaggle.com/competitions/godaddy-microbusiness-density-forecasting/overview).
**The dataset consists of monthly microbusiness data for US counties from 2019 to 2022 (39 months), and the goal is to forecast next 8 months' microbusiness density for each county.**


For this project, we will replicate a **deep neural architecture based on backward and forward residual links and a very deep stack of fully-connected layers** as given in [N-BEATS: Neural basis expansion analysis for interpretable time series forecasting](https://arxiv.org/abs/1905.10437) paper. We will make our predictions using an **ensemble** of deep neural networks trained with different hyperparameters and different length of past history. The model is evaluated using symmetric mean absolute percentage error(**sMAPE**) because the scale of microbusiness density data is different for different counties.


Below is the abstract of the original NBEATS paper for reference. 

```We focus on solving the univariate times series point forecasting problem using deep learning. We propose a deep neural architecture based on backward and forward residual links and a very deep stack of fully-connected layers. The architecture has a number of desirable properties, being interpretable, applicable without modification to a wide array of target domains, and fast to train. We test the proposed architecture on several well-known datasets, including M3, M4 and TOURISM competition datasets containing time series from diverse domains. We demonstrate state-of-the-art performance for two configurations of N-BEATS for all the datasets, improving forecast accuracy by 11% over a statistical benchmark and by 3% over last year's winner of the M4 competition, a domain-adjusted hand-crafted hybrid between neural network and statistical time series models. The first configuration of our model does not employ any time-series-specific components and its performance on heterogeneous datasets strongly suggests that, contrarily to received wisdom, deep learning primitives such as residual blocks are by themselves sufficient to solve a wide range of forecasting problems. Finally, we demonstrate how the proposed architecture can be augmented to provide outputs that are interpretable without considerable loss in accuracy. (Boris N. Oreshkin, Dmitri Carpov, Nicolas Chapados, Yoshua Bengio)```
